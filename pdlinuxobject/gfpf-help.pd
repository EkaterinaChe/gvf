#N canvas 371 151 555 490 10;
#X obj -19 -133 cnv 15 552 40 empty \$0-pddp.cnv.header gfpf 3 12 1
18 -149995 -216373 0;
#X msg 3 -28 learn 0;
#X text 89 -29 learn gesture template 0;
#X text 110 0 send data to the object. If previsouly pushed "learn
i" \, template i is filled. If previously pushed "follow" \, data are
live geture observations and use for recognition;
#X msg 29 54 follow;
#N canvas 879 251 450 300 more 0;
#X floatatom 29 6 5 0 0 0 - - -;
#X msg 29 37 tolerance \$1;
#X msg 68 178 adaptation_speed \$1 \$2 \$3 \$4;
#X floatatom 71 84 15 0 0 0 Phase - -;
#X connect 0 0 1 0;
#X restore 225 166 pd more;
#X msg 15 1 data \$1 \$2;
#X floatatom -3 216 10 0 0 3 Phase - -;
#X floatatom 66 216 10 0 0 3 Speed - -;
#X floatatom 136 216 10 0 0 3 Scaling - -;
#X floatatom 206 217 10 0 0 3 Angle_rotation - -;
#X floatatom 294 217 10 0 0 3 Recognition - -;
#X obj -3 166 gfpf help patch ------------------;
#X text 94 54 follow: recognize in realtime the live gesture performed
as one of the template rcorded. In addition estimate variations of
the live gesture according to the templates (e.g. if the gesture is
performed bigger \, smaller \, faster \, slower);
#X connect 1 0 12 0;
#X connect 4 0 12 0;
#X connect 6 0 12 0;
#X connect 12 0 7 0;
#X connect 12 1 8 0;
#X connect 12 2 9 0;
#X connect 12 3 10 0;
#X connect 12 4 11 0;
